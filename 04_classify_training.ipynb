{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/yq/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/yq/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from model import SVHNNet\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.extract_patch import ExtractPatch\n",
    "from utils.mean_subtract import MeanSubtract\n",
    "from utils.generator import Generator\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 54\n",
    "height = 54\n",
    "depth = 3\n",
    "classes = 11\n",
    "BS = 128\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain the model on the extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pickle.load(open(\"rgb_means.pkl\", \"rb\"))\n",
    "\n",
    "ep = ExtractPatch(width, height)\n",
    "ms = MeanSubtract(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "preprocessors = [ep, ms]\n",
    "\n",
    "generator = Generator(\"hdf5/extra_train.hdf5\", BS, epochs, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 54, 54, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 54, 54, 48)   3648        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 54, 54, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 54, 54, 48)   192         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 48)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 27, 27, 48)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 27, 27, 64)   76864       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 27, 27, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 27, 27, 64)   256         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 27, 27, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 27, 27, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 27, 27, 128)  204928      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 27, 27, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 27, 27, 128)  512         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 128)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 160)  512160      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 14, 14, 160)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 14, 14, 160)  640         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 160)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 160)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 192)  768192      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 14, 14, 192)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 192)  768         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 192)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 192)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 192)    921792      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 192)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 192)    768         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 192)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 192)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 192)    921792      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 192)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 192)    768         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 192)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4, 4, 192)    0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 192)    921792      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 192)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 192)    768         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 192)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4, 4, 192)    0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3072)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3072)         9440256     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3072)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 3072)         0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3072)         9440256     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 3072)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 3072)         0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           33803       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 11)           33803       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 11)           33803       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 11)           33803       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 11)           33803       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 6)            18438       dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,403,805\n",
      "Trainable params: 23,401,469\n",
      "Non-trainable params: 2,336\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SVHNNet.build(height, width, depth, classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "# exponential decay\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "callbacks = [TensorBoard(\"logs\", batch_size=BS, write_images=True),\n",
    "            LearningRateScheduler(exp_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yq/miniconda3/envs/tf/lib/python3.6/site-packages/sklearn/feature_extraction/image.py:287: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  indexing_strides = arr[slices].strides\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1580 [==============================] - 107s 68ms/step - loss: 4.9506 - dense_3_loss: 1.3708 - dense_4_loss: 1.6243 - dense_5_loss: 1.1973 - dense_6_loss: 0.2761 - dense_7_loss: 0.0093 - dense_8_loss: 0.4728 - dense_3_acc: 0.5585 - dense_4_acc: 0.4636 - dense_5_acc: 0.6296 - dense_6_acc: 0.9357 - dense_7_acc: 0.9988 - dense_8_acc: 0.84704s - loss: 5.0091 - dense_3_loss: 1.3899 - dense_4_loss: 1.6436 - dense_5_loss: 1.2140 - dense_6_loss: 0.2789 - dense_7_loss: 0.0095 - dense_8_loss: 0.4733 - dense_3_acc: 0.5500 - dense_4_acc: 0.4540 - dense_5_acc: 0\n",
      "Epoch 2/10\n",
      "1580/1580 [==============================] - 105s 67ms/step - loss: 2.5448 - dense_3_loss: 0.6802 - dense_4_loss: 0.8168 - dense_5_loss: 0.5998 - dense_6_loss: 0.1608 - dense_7_loss: 0.0056 - dense_8_loss: 0.2816 - dense_3_acc: 0.8267 - dense_4_acc: 0.7872 - dense_5_acc: 0.8394 - dense_6_acc: 0.9573 - dense_7_acc: 0.9994 - dense_8_acc: 0.9304\n",
      "Epoch 3/10\n",
      "1580/1580 [==============================] - 106s 67ms/step - loss: 1.6879 - dense_3_loss: 0.4531 - dense_4_loss: 0.5331 - dense_5_loss: 0.3961 - dense_6_loss: 0.1169 - dense_7_loss: 0.0051 - dense_8_loss: 0.1836 - dense_3_acc: 0.8831 - dense_4_acc: 0.8626 - dense_5_acc: 0.8920 - dense_6_acc: 0.9690 - dense_7_acc: 0.9994 - dense_8_acc: 0.95347s - loss: 1.7290 - dense_3_loss: 0.4648 - dense_4_loss: 0.5468 - dense_5_loss: 0.4043 - dense_6_loss: 0.1190 - dense_7_loss: 0.0051 - dense_8_loss: 0.1889 - dense_3_acc: 0\n",
      "Epoch 4/10\n",
      "1580/1580 [==============================] - 106s 67ms/step - loss: 0.9887 - dense_3_loss: 0.2509 - dense_4_loss: 0.2947 - dense_5_loss: 0.2511 - dense_6_loss: 0.0823 - dense_7_loss: 0.0043 - dense_8_loss: 0.1054 - dense_3_acc: 0.9267 - dense_4_acc: 0.9155 - dense_5_acc: 0.9294 - dense_6_acc: 0.9780 - dense_7_acc: 0.9994 - dense_8_acc: 0.96769s - loss: 0.9959 - dense_3_loss: 0.2532 - dense_4_loss: 0.2963 - dense_5_loss: 0.2533 - dense_6_loss: 0.0832 - dense_7_loss: 0.0044 - dense_8_loss\n",
      "Epoch 5/10\n",
      "1580/1580 [==============================] - 106s 67ms/step - loss: 0.8674 - dense_3_loss: 0.2269 - dense_4_loss: 0.2610 - dense_5_loss: 0.2120 - dense_6_loss: 0.0683 - dense_7_loss: 0.0041 - dense_8_loss: 0.0951 - dense_3_acc: 0.9348 - dense_4_acc: 0.9253 - dense_5_acc: 0.9415 - dense_6_acc: 0.9821 - dense_7_acc: 0.9994 - dense_8_acc: 0.971610s - loss: 0.8836 - dense_3_loss: 0.2309 - dense_4_loss: 0.2659 - dense_5_loss: 0.2166 - dense_6_loss: 0.0699 - d\n",
      "Epoch 6/10\n",
      "1580/1580 [==============================] - 106s 67ms/step - loss: 0.7488 - dense_3_loss: 0.1977 - dense_4_loss: 0.2213 - dense_5_loss: 0.1808 - dense_6_loss: 0.0569 - dense_7_loss: 0.0037 - dense_8_loss: 0.0884 - dense_3_acc: 0.9433 - dense_4_acc: 0.9389 - dense_5_acc: 0.9515 - dense_6_acc: 0.9854 - dense_7_acc: 0.9994 - dense_8_acc: 0.973210s - loss: 0.7579 - dense_3_loss: 0.2005 - dense_4_loss: 0.2237 - dense_5_loss: 0.1823 - dense_6_loss: 0.0584 - dense_7_loss: 0.0038 - dense_8_loss: 0.0893 - dense_3_acc: 0.9426 - dense_4_acc: 0.9381 - dense_5_acc: 0.9509 - dense_6_acc: 0.9850 - dense_7_ac - ETA: 9s - loss: 0.7567 - dense_3_loss: 0.2001 - dense_4_loss: 0.2233 - dense_5_loss: 0.1821 - dense_6_loss: 0.0581 - dense_7_loss: 0.0038 - dense_8\n",
      "Epoch 7/10\n",
      "1580/1580 [==============================] - 105s 67ms/step - loss: 0.6521 - dense_3_loss: 0.1733 - dense_4_loss: 0.1938 - dense_5_loss: 0.1541 - dense_6_loss: 0.0488 - dense_7_loss: 0.0035 - dense_8_loss: 0.0787 - dense_3_acc: 0.9505 - dense_4_acc: 0.9474 - dense_5_acc: 0.9589 - dense_6_acc: 0.9878 - dense_7_acc: 0.9994 - dense_8_acc: 0.9759\n",
      "Epoch 8/10\n",
      "1580/1580 [==============================] - 105s 66ms/step - loss: 0.6388 - dense_3_loss: 0.1692 - dense_4_loss: 0.1888 - dense_5_loss: 0.1534 - dense_6_loss: 0.0469 - dense_7_loss: 0.0032 - dense_8_loss: 0.0774 - dense_3_acc: 0.9518 - dense_4_acc: 0.9479 - dense_5_acc: 0.9592 - dense_6_acc: 0.9879 - dense_7_acc: 0.9994 - dense_8_acc: 0.97608s - loss: 0.6418 - dense_3_loss: 0.1693 - dense_4_loss: 0.1898 - dense_5_loss: 0.1548 - dense_6_loss: 0.0472 - dense_7_loss: 0.0032 - dense_8_loss: 0.0775 - dense_\n",
      "Epoch 9/10\n",
      "1580/1580 [==============================] - 105s 66ms/step - loss: 0.5778 - dense_3_loss: 0.1545 - dense_4_loss: 0.1707 - dense_5_loss: 0.1374 - dense_6_loss: 0.0422 - dense_7_loss: 0.0029 - dense_8_loss: 0.0701 - dense_3_acc: 0.9554 - dense_4_acc: 0.9523 - dense_5_acc: 0.9634 - dense_6_acc: 0.9890 - dense_7_acc: 0.9995 - dense_8_acc: 0.9787\n",
      "Epoch 10/10\n",
      "1580/1580 [==============================] - 105s 66ms/step - loss: 0.5599 - dense_3_loss: 0.1506 - dense_4_loss: 0.1678 - dense_5_loss: 0.1326 - dense_6_loss: 0.0390 - dense_7_loss: 0.0026 - dense_8_loss: 0.0672 - dense_3_acc: 0.9563 - dense_4_acc: 0.9526 - dense_5_acc: 0.9648 - dense_6_acc: 0.9902 - dense_7_acc: 0.9994 - dense_8_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(generator.generate(), steps_per_epoch=generator.n_img//BS, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pretrain.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simply testing it\n",
    "test_img = cv2.imread(\"test.png\")\n",
    "ori_test = test_img.copy()\n",
    "test_img = cv2.resize(test_img, (54, 54))\n",
    "test_img = ms.preprocess(test_img)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "\n",
    "prediction = model.predict(test_img)\n",
    "\n",
    "value = []\n",
    "for pred in prediction:\n",
    "    value.append(np.argmax(pred))\n",
    "    \n",
    "print(value[:value[-1]])\n",
    "\n",
    "plt.imshow(cv2.cvtColor(ori_test, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.title(value[:value[-1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializa the generators\n",
    "\n",
    "train_gen = Generator(\"hdf5/train.hdf5\", BS, epochs, preprocessors)\n",
    "val_gen = Generator(\"hdf5/val.hdf5\", BS, epochs, preprocessors)\n",
    "\n",
    "# callbacks, add in earlystopping\n",
    "callbacks = [TensorBoard(\"logs\", batch_size=BS, write_images=True),\n",
    "            LearningRateScheduler(exp_decay),\n",
    "            EarlyStopping(monitor=\"val_loss\", min_delta=0.05, patience=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/241 [..............................] - ETA: 23s - loss: 2.1440 - dense_3_loss: 0.5418 - dense_4_loss: 0.6514 - dense_5_loss: 0.4573 - dense_6_loss: 0.0724 - dense_7_loss: 3.9426e-04 - dense_8_loss: 0.4207 - dense_3_acc: 0.8359 - dense_4_acc: 0.8086 - dense_5_acc: 0.8945 - dense_6_acc: 0.9844 - dense_7_acc: 1.0000 - dense_8_acc: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yq/miniconda3/envs/tf/lib/python3.6/site-packages/sklearn/feature_extraction/image.py:287: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  indexing_strides = arr[slices].strides\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 17s 69ms/step - loss: 1.1980 - dense_3_loss: 0.3671 - dense_4_loss: 0.3843 - dense_5_loss: 0.2202 - dense_6_loss: 0.0628 - dense_7_loss: 0.0029 - dense_8_loss: 0.1607 - dense_3_acc: 0.8940 - dense_4_acc: 0.8924 - dense_5_acc: 0.9426 - dense_6_acc: 0.9841 - dense_7_acc: 0.9997 - dense_8_acc: 0.9490 - val_loss: 0.8145 - val_dense_3_loss: 0.2546 - val_dense_4_loss: 0.2527 - val_dense_5_loss: 0.1664 - val_dense_6_loss: 0.0354 - val_dense_7_loss: 0.0015 - val_dense_8_loss: 0.1039 - val_dense_3_acc: 0.9268 - val_dense_4_acc: 0.9309 - val_dense_5_acc: 0.9572 - val_dense_6_acc: 0.9897 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9667\n",
      "Epoch 2/200\n",
      "241/241 [==============================] - 17s 69ms/step - loss: 1.2613 - dense_3_loss: 0.3990 - dense_4_loss: 0.4146 - dense_5_loss: 0.2048 - dense_6_loss: 0.0527 - dense_7_loss: 0.0020 - dense_8_loss: 0.1882 - dense_3_acc: 0.9044 - dense_4_acc: 0.8979 - dense_5_acc: 0.9453 - dense_6_acc: 0.9862 - dense_7_acc: 0.9997 - dense_8_acc: 0.9558 - val_loss: 0.8079 - val_dense_3_loss: 0.2771 - val_dense_4_loss: 0.2609 - val_dense_5_loss: 0.1462 - val_dense_6_loss: 0.0283 - val_dense_7_loss: 5.0655e-04 - val_dense_8_loss: 0.0948 - val_dense_3_acc: 0.9266 - val_dense_4_acc: 0.9220 - val_dense_5_acc: 0.9612 - val_dense_6_acc: 0.9916 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9663\n",
      "Epoch 3/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 1.3711 - dense_3_loss: 0.4694 - dense_4_loss: 0.4297 - dense_5_loss: 0.2061 - dense_6_loss: 0.0502 - dense_7_loss: 0.0019 - dense_8_loss: 0.2138 - dense_3_acc: 0.8951 - dense_4_acc: 0.8939 - dense_5_acc: 0.9438 - dense_6_acc: 0.9869 - dense_7_acc: 0.9997 - dense_8_acc: 0.9530 - val_loss: 1.4775 - val_dense_3_loss: 0.4992 - val_dense_4_loss: 0.4654 - val_dense_5_loss: 0.2261 - val_dense_6_loss: 0.0454 - val_dense_7_loss: 0.0016 - val_dense_8_loss: 0.2398 - val_dense_3_acc: 0.8942 - val_dense_4_acc: 0.9035 - val_dense_5_acc: 0.9490 - val_dense_6_acc: 0.9874 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9553\n",
      "Epoch 4/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 1.4713 - dense_3_loss: 0.5348 - dense_4_loss: 0.4519 - dense_5_loss: 0.2235 - dense_6_loss: 0.0560 - dense_7_loss: 0.0018 - dense_8_loss: 0.2033 - dense_3_acc: 0.8773 - dense_4_acc: 0.8804 - dense_5_acc: 0.9394 - dense_6_acc: 0.9852 - dense_7_acc: 0.9997 - dense_8_acc: 0.9494 - val_loss: 1.0019 - val_dense_3_loss: 0.3640 - val_dense_4_loss: 0.3143 - val_dense_5_loss: 0.1730 - val_dense_6_loss: 0.0419 - val_dense_7_loss: 8.5390e-04 - val_dense_8_loss: 0.1080 - val_dense_3_acc: 0.9169 - val_dense_4_acc: 0.9127 - val_dense_5_acc: 0.9536 - val_dense_6_acc: 0.9886 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9654\n",
      "Epoch 5/200\n",
      "241/241 [==============================] - 17s 68ms/step - loss: 1.1887 - dense_3_loss: 0.4416 - dense_4_loss: 0.3633 - dense_5_loss: 0.1853 - dense_6_loss: 0.0447 - dense_7_loss: 0.0013 - dense_8_loss: 0.1525 - dense_3_acc: 0.8994 - dense_4_acc: 0.9023 - dense_5_acc: 0.9466 - dense_6_acc: 0.9873 - dense_7_acc: 0.9997 - dense_8_acc: 0.9589 - val_loss: 1.0175 - val_dense_3_loss: 0.3951 - val_dense_4_loss: 0.2877 - val_dense_5_loss: 0.1779 - val_dense_6_loss: 0.0477 - val_dense_7_loss: 0.0015 - val_dense_8_loss: 0.1077 - val_dense_3_acc: 0.9102 - val_dense_4_acc: 0.9144 - val_dense_5_acc: 0.9524 - val_dense_6_acc: 0.9869 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9633\n",
      "Epoch 6/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 1.2955 - dense_3_loss: 0.4595 - dense_4_loss: 0.3971 - dense_5_loss: 0.1854 - dense_6_loss: 0.0454 - dense_7_loss: 0.0013 - dense_8_loss: 0.2069 - dense_3_acc: 0.8922 - dense_4_acc: 0.8917 - dense_5_acc: 0.9475 - dense_6_acc: 0.9875 - dense_7_acc: 0.9997 - dense_8_acc: 0.9538 - val_loss: 0.9429 - val_dense_3_loss: 0.3435 - val_dense_4_loss: 0.2905 - val_dense_5_loss: 0.1637 - val_dense_6_loss: 0.0381 - val_dense_7_loss: 5.3081e-04 - val_dense_8_loss: 0.1065 - val_dense_3_acc: 0.9068 - val_dense_4_acc: 0.9191 - val_dense_5_acc: 0.9562 - val_dense_6_acc: 0.9886 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9718\n",
      "Epoch 7/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 1.1505 - dense_3_loss: 0.4116 - dense_4_loss: 0.3635 - dense_5_loss: 0.1784 - dense_6_loss: 0.0439 - dense_7_loss: 9.4492e-04 - dense_8_loss: 0.1522 - dense_3_acc: 0.9018 - dense_4_acc: 0.9038 - dense_5_acc: 0.9513 - dense_6_acc: 0.9883 - dense_7_acc: 0.9997 - dense_8_acc: 0.9619 - val_loss: 0.8213 - val_dense_3_loss: 0.2915 - val_dense_4_loss: 0.2555 - val_dense_5_loss: 0.1512 - val_dense_6_loss: 0.0350 - val_dense_7_loss: 5.8143e-04 - val_dense_8_loss: 0.0875 - val_dense_3_acc: 0.9136 - val_dense_4_acc: 0.9262 - val_dense_5_acc: 0.9583 - val_dense_6_acc: 0.9907 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9680\n",
      "Epoch 8/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.9991 - dense_3_loss: 0.3799 - dense_4_loss: 0.3026 - dense_5_loss: 0.1556 - dense_6_loss: 0.0397 - dense_7_loss: 8.3935e-04 - dense_8_loss: 0.1204 - dense_3_acc: 0.9114 - dense_4_acc: 0.9154 - dense_5_acc: 0.9552 - dense_6_acc: 0.9888 - dense_7_acc: 0.9998 - dense_8_acc: 0.9668 - val_loss: 0.9553 - val_dense_3_loss: 0.3795 - val_dense_4_loss: 0.2694 - val_dense_5_loss: 0.1549 - val_dense_6_loss: 0.0375 - val_dense_7_loss: 0.0017 - val_dense_8_loss: 0.1123 - val_dense_3_acc: 0.9203 - val_dense_4_acc: 0.9296 - val_dense_5_acc: 0.9621 - val_dense_6_acc: 0.9907 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9696\n",
      "Epoch 9/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.9997 - dense_3_loss: 0.3859 - dense_4_loss: 0.3034 - dense_5_loss: 0.1508 - dense_6_loss: 0.0339 - dense_7_loss: 0.0011 - dense_8_loss: 0.1245 - dense_3_acc: 0.9088 - dense_4_acc: 0.9174 - dense_5_acc: 0.9564 - dense_6_acc: 0.9901 - dense_7_acc: 0.9998 - dense_8_acc: 0.9657 - val_loss: 0.8239 - val_dense_3_loss: 0.2997 - val_dense_4_loss: 0.2635 - val_dense_5_loss: 0.1351 - val_dense_6_loss: 0.0293 - val_dense_7_loss: 5.5829e-04 - val_dense_8_loss: 0.0957 - val_dense_3_acc: 0.9292 - val_dense_4_acc: 0.9313 - val_dense_5_acc: 0.9633 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9701\n",
      "Epoch 10/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.8756 - dense_3_loss: 0.3341 - dense_4_loss: 0.2711 - dense_5_loss: 0.1307 - dense_6_loss: 0.0320 - dense_7_loss: 4.0669e-04 - dense_8_loss: 0.1074 - dense_3_acc: 0.9206 - dense_4_acc: 0.9263 - dense_5_acc: 0.9605 - dense_6_acc: 0.9907 - dense_7_acc: 0.9998 - dense_8_acc: 0.9716 - val_loss: 0.8113 - val_dense_3_loss: 0.2875 - val_dense_4_loss: 0.2384 - val_dense_5_loss: 0.1387 - val_dense_6_loss: 0.0435 - val_dense_7_loss: 6.0011e-04 - val_dense_8_loss: 0.1027 - val_dense_3_acc: 0.9359 - val_dense_4_acc: 0.9435 - val_dense_5_acc: 0.9599 - val_dense_6_acc: 0.9890 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9722\n",
      "Epoch 11/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.8160 - dense_3_loss: 0.3100 - dense_4_loss: 0.2507 - dense_5_loss: 0.1246 - dense_6_loss: 0.0327 - dense_7_loss: 6.7613e-04 - dense_8_loss: 0.0974 - dense_3_acc: 0.9274 - dense_4_acc: 0.9307 - dense_5_acc: 0.9617 - dense_6_acc: 0.9907 - dense_7_acc: 0.9998 - dense_8_acc: 0.9740 - val_loss: 0.8103 - val_dense_3_loss: 0.2802 - val_dense_4_loss: 0.2459 - val_dense_5_loss: 0.1579 - val_dense_6_loss: 0.0340 - val_dense_7_loss: 6.7162e-04 - val_dense_8_loss: 0.0916 - val_dense_3_acc: 0.9338 - val_dense_4_acc: 0.9351 - val_dense_5_acc: 0.9616 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9726\n",
      "Epoch 12/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.7836 - dense_3_loss: 0.2998 - dense_4_loss: 0.2401 - dense_5_loss: 0.1227 - dense_6_loss: 0.0286 - dense_7_loss: 0.0010 - dense_8_loss: 0.0913 - dense_3_acc: 0.9287 - dense_4_acc: 0.9332 - dense_5_acc: 0.9629 - dense_6_acc: 0.9920 - dense_7_acc: 0.9998 - dense_8_acc: 0.9753 - val_loss: 0.8457 - val_dense_3_loss: 0.2977 - val_dense_4_loss: 0.2599 - val_dense_5_loss: 0.1458 - val_dense_6_loss: 0.0400 - val_dense_7_loss: 9.7224e-04 - val_dense_8_loss: 0.1013 - val_dense_3_acc: 0.9351 - val_dense_4_acc: 0.9363 - val_dense_5_acc: 0.9646 - val_dense_6_acc: 0.9920 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.7302 - dense_3_loss: 0.2794 - dense_4_loss: 0.2275 - dense_5_loss: 0.1110 - dense_6_loss: 0.0265 - dense_7_loss: 5.2112e-04 - dense_8_loss: 0.0852 - dense_3_acc: 0.9325 - dense_4_acc: 0.9351 - dense_5_acc: 0.9652 - dense_6_acc: 0.9921 - dense_7_acc: 0.9998 - dense_8_acc: 0.9761 - val_loss: 0.8079 - val_dense_3_loss: 0.2866 - val_dense_4_loss: 0.2405 - val_dense_5_loss: 0.1544 - val_dense_6_loss: 0.0344 - val_dense_7_loss: 9.5975e-04 - val_dense_8_loss: 0.0911 - val_dense_3_acc: 0.9338 - val_dense_4_acc: 0.9347 - val_dense_5_acc: 0.9646 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9739\n",
      "Epoch 14/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.7498 - dense_3_loss: 0.2807 - dense_4_loss: 0.2377 - dense_5_loss: 0.1131 - dense_6_loss: 0.0250 - dense_7_loss: 4.7549e-04 - dense_8_loss: 0.0928 - dense_3_acc: 0.9302 - dense_4_acc: 0.9341 - dense_5_acc: 0.9661 - dense_6_acc: 0.9927 - dense_7_acc: 0.9999 - dense_8_acc: 0.9757 - val_loss: 0.7382 - val_dense_3_loss: 0.2479 - val_dense_4_loss: 0.2419 - val_dense_5_loss: 0.1369 - val_dense_6_loss: 0.0297 - val_dense_7_loss: 0.0023 - val_dense_8_loss: 0.0795 - val_dense_3_acc: 0.9351 - val_dense_4_acc: 0.9384 - val_dense_5_acc: 0.9633 - val_dense_6_acc: 0.9937 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9739\n",
      "Epoch 15/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.7030 - dense_3_loss: 0.2715 - dense_4_loss: 0.2147 - dense_5_loss: 0.1106 - dense_6_loss: 0.0257 - dense_7_loss: 3.8024e-04 - dense_8_loss: 0.0802 - dense_3_acc: 0.9341 - dense_4_acc: 0.9390 - dense_5_acc: 0.9673 - dense_6_acc: 0.9924 - dense_7_acc: 0.9999 - dense_8_acc: 0.9767 - val_loss: 0.7548 - val_dense_3_loss: 0.2526 - val_dense_4_loss: 0.2287 - val_dense_5_loss: 0.1481 - val_dense_6_loss: 0.0299 - val_dense_7_loss: 0.0024 - val_dense_8_loss: 0.0932 - val_dense_3_acc: 0.9389 - val_dense_4_acc: 0.9401 - val_dense_5_acc: 0.9642 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9739\n",
      "Epoch 16/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.6596 - dense_3_loss: 0.2499 - dense_4_loss: 0.2101 - dense_5_loss: 0.1058 - dense_6_loss: 0.0232 - dense_7_loss: 3.4599e-04 - dense_8_loss: 0.0704 - dense_3_acc: 0.9377 - dense_4_acc: 0.9382 - dense_5_acc: 0.9674 - dense_6_acc: 0.9930 - dense_7_acc: 0.9999 - dense_8_acc: 0.9775 - val_loss: 0.7371 - val_dense_3_loss: 0.2620 - val_dense_4_loss: 0.2287 - val_dense_5_loss: 0.1494 - val_dense_6_loss: 0.0239 - val_dense_7_loss: 7.2250e-04 - val_dense_8_loss: 0.0723 - val_dense_3_acc: 0.9342 - val_dense_4_acc: 0.9351 - val_dense_5_acc: 0.9654 - val_dense_6_acc: 0.9941 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9781\n",
      "Epoch 17/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.6337 - dense_3_loss: 0.2491 - dense_4_loss: 0.1961 - dense_5_loss: 0.1015 - dense_6_loss: 0.0223 - dense_7_loss: 3.5806e-04 - dense_8_loss: 0.0644 - dense_3_acc: 0.9360 - dense_4_acc: 0.9407 - dense_5_acc: 0.9680 - dense_6_acc: 0.9935 - dense_7_acc: 0.9999 - dense_8_acc: 0.9795 - val_loss: 0.7153 - val_dense_3_loss: 0.2807 - val_dense_4_loss: 0.2092 - val_dense_5_loss: 0.1324 - val_dense_6_loss: 0.0267 - val_dense_7_loss: 7.4881e-04 - val_dense_8_loss: 0.0655 - val_dense_3_acc: 0.9431 - val_dense_4_acc: 0.9414 - val_dense_5_acc: 0.9680 - val_dense_6_acc: 0.9924 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9793\n",
      "Epoch 18/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.5905 - dense_3_loss: 0.2147 - dense_4_loss: 0.1885 - dense_5_loss: 0.0996 - dense_6_loss: 0.0222 - dense_7_loss: 4.1244e-04 - dense_8_loss: 0.0651 - dense_3_acc: 0.9403 - dense_4_acc: 0.9435 - dense_5_acc: 0.9688 - dense_6_acc: 0.9928 - dense_7_acc: 0.9998 - dense_8_acc: 0.9788 - val_loss: 0.7467 - val_dense_3_loss: 0.2710 - val_dense_4_loss: 0.2243 - val_dense_5_loss: 0.1383 - val_dense_6_loss: 0.0354 - val_dense_7_loss: 0.0021 - val_dense_8_loss: 0.0756 - val_dense_3_acc: 0.9355 - val_dense_4_acc: 0.9414 - val_dense_5_acc: 0.9642 - val_dense_6_acc: 0.9911 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9751\n",
      "Epoch 19/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.5489 - dense_3_loss: 0.2018 - dense_4_loss: 0.1792 - dense_5_loss: 0.0901 - dense_6_loss: 0.0196 - dense_7_loss: 5.1970e-04 - dense_8_loss: 0.0577 - dense_3_acc: 0.9413 - dense_4_acc: 0.9454 - dense_5_acc: 0.9721 - dense_6_acc: 0.9941 - dense_7_acc: 0.9999 - dense_8_acc: 0.9809 - val_loss: 0.7349 - val_dense_3_loss: 0.2424 - val_dense_4_loss: 0.2292 - val_dense_5_loss: 0.1367 - val_dense_6_loss: 0.0371 - val_dense_7_loss: 0.0026 - val_dense_8_loss: 0.0869 - val_dense_3_acc: 0.9431 - val_dense_4_acc: 0.9414 - val_dense_5_acc: 0.9650 - val_dense_6_acc: 0.9916 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9734\n",
      "Epoch 20/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.5072 - dense_3_loss: 0.1800 - dense_4_loss: 0.1697 - dense_5_loss: 0.0863 - dense_6_loss: 0.0189 - dense_7_loss: 4.3175e-04 - dense_8_loss: 0.0519 - dense_3_acc: 0.9440 - dense_4_acc: 0.9478 - dense_5_acc: 0.9734 - dense_6_acc: 0.9936 - dense_7_acc: 0.9999 - dense_8_acc: 0.9823 - val_loss: 0.6595 - val_dense_3_loss: 0.2235 - val_dense_4_loss: 0.2142 - val_dense_5_loss: 0.1285 - val_dense_6_loss: 0.0265 - val_dense_7_loss: 0.0011 - val_dense_8_loss: 0.0657 - val_dense_3_acc: 0.9452 - val_dense_4_acc: 0.9401 - val_dense_5_acc: 0.9696 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9785\n",
      "Epoch 21/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4884 - dense_3_loss: 0.1777 - dense_4_loss: 0.1632 - dense_5_loss: 0.0813 - dense_6_loss: 0.0188 - dense_7_loss: 4.2313e-04 - dense_8_loss: 0.0471 - dense_3_acc: 0.9443 - dense_4_acc: 0.9496 - dense_5_acc: 0.9744 - dense_6_acc: 0.9942 - dense_7_acc: 1.0000 - dense_8_acc: 0.9834 - val_loss: 0.7216 - val_dense_3_loss: 0.2309 - val_dense_4_loss: 0.2216 - val_dense_5_loss: 0.1486 - val_dense_6_loss: 0.0349 - val_dense_7_loss: 0.0015 - val_dense_8_loss: 0.0841 - val_dense_3_acc: 0.9428 - val_dense_4_acc: 0.9482 - val_dense_5_acc: 0.9622 - val_dense_6_acc: 0.9914 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9753\n",
      "Epoch 22/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4883 - dense_3_loss: 0.1736 - dense_4_loss: 0.1622 - dense_5_loss: 0.0847 - dense_6_loss: 0.0172 - dense_7_loss: 4.6332e-04 - dense_8_loss: 0.0501 - dense_3_acc: 0.9468 - dense_4_acc: 0.9489 - dense_5_acc: 0.9725 - dense_6_acc: 0.9946 - dense_7_acc: 0.9999 - dense_8_acc: 0.9821 - val_loss: 0.7095 - val_dense_3_loss: 0.2342 - val_dense_4_loss: 0.2209 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.0305 - val_dense_7_loss: 3.8688e-06 - val_dense_8_loss: 0.0801 - val_dense_3_acc: 0.9494 - val_dense_4_acc: 0.9431 - val_dense_5_acc: 0.9663 - val_dense_6_acc: 0.9907 - val_dense_7_acc: 1.0000 - val_dense_8_acc: 0.9755\n",
      "Epoch 23/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4832 - dense_3_loss: 0.1678 - dense_4_loss: 0.1610 - dense_5_loss: 0.0848 - dense_6_loss: 0.0187 - dense_7_loss: 4.8854e-04 - dense_8_loss: 0.0505 - dense_3_acc: 0.9487 - dense_4_acc: 0.9502 - dense_5_acc: 0.9730 - dense_6_acc: 0.9947 - dense_7_acc: 0.9999 - dense_8_acc: 0.9831 - val_loss: 0.6919 - val_dense_3_loss: 0.2225 - val_dense_4_loss: 0.2247 - val_dense_5_loss: 0.1316 - val_dense_6_loss: 0.0317 - val_dense_7_loss: 0.0036 - val_dense_8_loss: 0.0777 - val_dense_3_acc: 0.9486 - val_dense_4_acc: 0.9410 - val_dense_5_acc: 0.9671 - val_dense_6_acc: 0.9907 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9764\n",
      "Epoch 24/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4607 - dense_3_loss: 0.1625 - dense_4_loss: 0.1567 - dense_5_loss: 0.0786 - dense_6_loss: 0.0160 - dense_7_loss: 3.5357e-04 - dense_8_loss: 0.0465 - dense_3_acc: 0.9497 - dense_4_acc: 0.9519 - dense_5_acc: 0.9752 - dense_6_acc: 0.9952 - dense_7_acc: 0.9999 - dense_8_acc: 0.9846 - val_loss: 0.7213 - val_dense_3_loss: 0.2547 - val_dense_4_loss: 0.2264 - val_dense_5_loss: 0.1388 - val_dense_6_loss: 0.0301 - val_dense_7_loss: 0.0011 - val_dense_8_loss: 0.0702 - val_dense_3_acc: 0.9439 - val_dense_4_acc: 0.9418 - val_dense_5_acc: 0.9671 - val_dense_6_acc: 0.9916 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4550 - dense_3_loss: 0.1613 - dense_4_loss: 0.1518 - dense_5_loss: 0.0775 - dense_6_loss: 0.0181 - dense_7_loss: 4.9775e-04 - dense_8_loss: 0.0458 - dense_3_acc: 0.9500 - dense_4_acc: 0.9522 - dense_5_acc: 0.9758 - dense_6_acc: 0.9950 - dense_7_acc: 0.9999 - dense_8_acc: 0.9843 - val_loss: 0.7726 - val_dense_3_loss: 0.2527 - val_dense_4_loss: 0.2258 - val_dense_5_loss: 0.1596 - val_dense_6_loss: 0.0390 - val_dense_7_loss: 0.0014 - val_dense_8_loss: 0.0940 - val_dense_3_acc: 0.9444 - val_dense_4_acc: 0.9460 - val_dense_5_acc: 0.9629 - val_dense_6_acc: 0.9924 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9739\n",
      "Epoch 26/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4546 - dense_3_loss: 0.1660 - dense_4_loss: 0.1484 - dense_5_loss: 0.0783 - dense_6_loss: 0.0173 - dense_7_loss: 2.8113e-04 - dense_8_loss: 0.0444 - dense_3_acc: 0.9494 - dense_4_acc: 0.9538 - dense_5_acc: 0.9745 - dense_6_acc: 0.9948 - dense_7_acc: 0.9999 - dense_8_acc: 0.9847 - val_loss: 0.7519 - val_dense_3_loss: 0.2733 - val_dense_4_loss: 0.2222 - val_dense_5_loss: 0.1403 - val_dense_6_loss: 0.0309 - val_dense_7_loss: 0.0032 - val_dense_8_loss: 0.0820 - val_dense_3_acc: 0.9380 - val_dense_4_acc: 0.9435 - val_dense_5_acc: 0.9680 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9751\n",
      "Epoch 27/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4279 - dense_3_loss: 0.1558 - dense_4_loss: 0.1464 - dense_5_loss: 0.0716 - dense_6_loss: 0.0132 - dense_7_loss: 3.1288e-04 - dense_8_loss: 0.0405 - dense_3_acc: 0.9511 - dense_4_acc: 0.9543 - dense_5_acc: 0.9766 - dense_6_acc: 0.9958 - dense_7_acc: 1.0000 - dense_8_acc: 0.9866 - val_loss: 0.7268 - val_dense_3_loss: 0.2412 - val_dense_4_loss: 0.2239 - val_dense_5_loss: 0.1445 - val_dense_6_loss: 0.0356 - val_dense_7_loss: 0.0023 - val_dense_8_loss: 0.0793 - val_dense_3_acc: 0.9448 - val_dense_4_acc: 0.9473 - val_dense_5_acc: 0.9646 - val_dense_6_acc: 0.9907 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9755\n",
      "Epoch 28/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4305 - dense_3_loss: 0.1574 - dense_4_loss: 0.1422 - dense_5_loss: 0.0720 - dense_6_loss: 0.0171 - dense_7_loss: 2.6285e-04 - dense_8_loss: 0.0416 - dense_3_acc: 0.9517 - dense_4_acc: 0.9558 - dense_5_acc: 0.9775 - dense_6_acc: 0.9947 - dense_7_acc: 0.9999 - dense_8_acc: 0.9860 - val_loss: 0.7236 - val_dense_3_loss: 0.2603 - val_dense_4_loss: 0.2171 - val_dense_5_loss: 0.1347 - val_dense_6_loss: 0.0329 - val_dense_7_loss: 0.0022 - val_dense_8_loss: 0.0764 - val_dense_3_acc: 0.9414 - val_dense_4_acc: 0.9448 - val_dense_5_acc: 0.9654 - val_dense_6_acc: 0.9907 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9768\n",
      "Epoch 29/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4168 - dense_3_loss: 0.1506 - dense_4_loss: 0.1406 - dense_5_loss: 0.0719 - dense_6_loss: 0.0134 - dense_7_loss: 4.2932e-04 - dense_8_loss: 0.0398 - dense_3_acc: 0.9522 - dense_4_acc: 0.9557 - dense_5_acc: 0.9765 - dense_6_acc: 0.9958 - dense_7_acc: 0.9999 - dense_8_acc: 0.9863 - val_loss: 0.6941 - val_dense_3_loss: 0.2433 - val_dense_4_loss: 0.2201 - val_dense_5_loss: 0.1328 - val_dense_6_loss: 0.0274 - val_dense_7_loss: 0.0018 - val_dense_8_loss: 0.0686 - val_dense_3_acc: 0.9486 - val_dense_4_acc: 0.9418 - val_dense_5_acc: 0.9680 - val_dense_6_acc: 0.9945 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9785\n",
      "Epoch 30/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4193 - dense_3_loss: 0.1515 - dense_4_loss: 0.1408 - dense_5_loss: 0.0694 - dense_6_loss: 0.0169 - dense_7_loss: 1.7688e-04 - dense_8_loss: 0.0405 - dense_3_acc: 0.9531 - dense_4_acc: 0.9562 - dense_5_acc: 0.9778 - dense_6_acc: 0.9944 - dense_7_acc: 1.0000 - dense_8_acc: 0.9863 - val_loss: 0.7616 - val_dense_3_loss: 0.2694 - val_dense_4_loss: 0.2244 - val_dense_5_loss: 0.1340 - val_dense_6_loss: 0.0436 - val_dense_7_loss: 9.3447e-04 - val_dense_8_loss: 0.0893 - val_dense_3_acc: 0.9414 - val_dense_4_acc: 0.9460 - val_dense_5_acc: 0.9671 - val_dense_6_acc: 0.9899 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9755\n",
      "Epoch 31/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4126 - dense_3_loss: 0.1484 - dense_4_loss: 0.1382 - dense_5_loss: 0.0722 - dense_6_loss: 0.0143 - dense_7_loss: 2.8666e-04 - dense_8_loss: 0.0393 - dense_3_acc: 0.9538 - dense_4_acc: 0.9564 - dense_5_acc: 0.9763 - dense_6_acc: 0.9957 - dense_7_acc: 0.9999 - dense_8_acc: 0.9858 - val_loss: 0.7315 - val_dense_3_loss: 0.2492 - val_dense_4_loss: 0.2228 - val_dense_5_loss: 0.1466 - val_dense_6_loss: 0.0288 - val_dense_7_loss: 0.0011 - val_dense_8_loss: 0.0831 - val_dense_3_acc: 0.9456 - val_dense_4_acc: 0.9435 - val_dense_5_acc: 0.9654 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9760\n",
      "Epoch 32/200\n",
      "241/241 [==============================] - 17s 69ms/step - loss: 0.4016 - dense_3_loss: 0.1467 - dense_4_loss: 0.1319 - dense_5_loss: 0.0720 - dense_6_loss: 0.0145 - dense_7_loss: 3.9832e-04 - dense_8_loss: 0.0362 - dense_3_acc: 0.9542 - dense_4_acc: 0.9585 - dense_5_acc: 0.9774 - dense_6_acc: 0.9960 - dense_7_acc: 0.9999 - dense_8_acc: 0.9869 - val_loss: 0.7338 - val_dense_3_loss: 0.2535 - val_dense_4_loss: 0.2264 - val_dense_5_loss: 0.1394 - val_dense_6_loss: 0.0343 - val_dense_7_loss: 0.0034 - val_dense_8_loss: 0.0768 - val_dense_3_acc: 0.9460 - val_dense_4_acc: 0.9431 - val_dense_5_acc: 0.9667 - val_dense_6_acc: 0.9924 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9760\n",
      "Epoch 33/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3995 - dense_3_loss: 0.1494 - dense_4_loss: 0.1305 - dense_5_loss: 0.0682 - dense_6_loss: 0.0143 - dense_7_loss: 3.3920e-04 - dense_8_loss: 0.0367 - dense_3_acc: 0.9540 - dense_4_acc: 0.9573 - dense_5_acc: 0.9774 - dense_6_acc: 0.9956 - dense_7_acc: 0.9999 - dense_8_acc: 0.9877 - val_loss: 0.7320 - val_dense_3_loss: 0.2452 - val_dense_4_loss: 0.2324 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.0291 - val_dense_7_loss: 0.0011 - val_dense_8_loss: 0.0805 - val_dense_3_acc: 0.9444 - val_dense_4_acc: 0.9439 - val_dense_5_acc: 0.9675 - val_dense_6_acc: 0.9924 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9798\n",
      "Epoch 34/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.4019 - dense_3_loss: 0.1457 - dense_4_loss: 0.1346 - dense_5_loss: 0.0689 - dense_6_loss: 0.0146 - dense_7_loss: 3.9942e-05 - dense_8_loss: 0.0382 - dense_3_acc: 0.9537 - dense_4_acc: 0.9568 - dense_5_acc: 0.9776 - dense_6_acc: 0.9954 - dense_7_acc: 1.0000 - dense_8_acc: 0.9865 - val_loss: 0.6688 - val_dense_3_loss: 0.2232 - val_dense_4_loss: 0.2176 - val_dense_5_loss: 0.1336 - val_dense_6_loss: 0.0257 - val_dense_7_loss: 0.0018 - val_dense_8_loss: 0.0670 - val_dense_3_acc: 0.9460 - val_dense_4_acc: 0.9456 - val_dense_5_acc: 0.9667 - val_dense_6_acc: 0.9933 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9798\n",
      "Epoch 35/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3926 - dense_3_loss: 0.1472 - dense_4_loss: 0.1300 - dense_5_loss: 0.0650 - dense_6_loss: 0.0136 - dense_7_loss: 3.0296e-04 - dense_8_loss: 0.0365 - dense_3_acc: 0.9548 - dense_4_acc: 0.9581 - dense_5_acc: 0.9796 - dense_6_acc: 0.9960 - dense_7_acc: 1.0000 - dense_8_acc: 0.9870 - val_loss: 0.7001 - val_dense_3_loss: 0.2396 - val_dense_4_loss: 0.2064 - val_dense_5_loss: 0.1458 - val_dense_6_loss: 0.0285 - val_dense_7_loss: 0.0020 - val_dense_8_loss: 0.0778 - val_dense_3_acc: 0.9448 - val_dense_4_acc: 0.9477 - val_dense_5_acc: 0.9663 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9768\n",
      "Epoch 36/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3876 - dense_3_loss: 0.1455 - dense_4_loss: 0.1288 - dense_5_loss: 0.0637 - dense_6_loss: 0.0134 - dense_7_loss: 7.0755e-05 - dense_8_loss: 0.0362 - dense_3_acc: 0.9539 - dense_4_acc: 0.9584 - dense_5_acc: 0.9788 - dense_6_acc: 0.9959 - dense_7_acc: 1.0000 - dense_8_acc: 0.9869 - val_loss: 0.7388 - val_dense_3_loss: 0.2505 - val_dense_4_loss: 0.2311 - val_dense_5_loss: 0.1483 - val_dense_6_loss: 0.0243 - val_dense_7_loss: 0.0024 - val_dense_8_loss: 0.0822 - val_dense_3_acc: 0.9435 - val_dense_4_acc: 0.9427 - val_dense_5_acc: 0.9675 - val_dense_6_acc: 0.9954 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3865 - dense_3_loss: 0.1461 - dense_4_loss: 0.1282 - dense_5_loss: 0.0637 - dense_6_loss: 0.0142 - dense_7_loss: 1.4181e-04 - dense_8_loss: 0.0342 - dense_3_acc: 0.9548 - dense_4_acc: 0.9592 - dense_5_acc: 0.9787 - dense_6_acc: 0.9958 - dense_7_acc: 0.9999 - dense_8_acc: 0.9876 - val_loss: 0.7097 - val_dense_3_loss: 0.2334 - val_dense_4_loss: 0.2319 - val_dense_5_loss: 0.1357 - val_dense_6_loss: 0.0265 - val_dense_7_loss: 0.0017 - val_dense_8_loss: 0.0805 - val_dense_3_acc: 0.9452 - val_dense_4_acc: 0.9448 - val_dense_5_acc: 0.9667 - val_dense_6_acc: 0.9928 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9777\n",
      "Epoch 38/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3868 - dense_3_loss: 0.1411 - dense_4_loss: 0.1281 - dense_5_loss: 0.0692 - dense_6_loss: 0.0120 - dense_7_loss: 4.1743e-04 - dense_8_loss: 0.0360 - dense_3_acc: 0.9554 - dense_4_acc: 0.9595 - dense_5_acc: 0.9781 - dense_6_acc: 0.9962 - dense_7_acc: 0.9999 - dense_8_acc: 0.9875 - val_loss: 0.7456 - val_dense_3_loss: 0.2573 - val_dense_4_loss: 0.2301 - val_dense_5_loss: 0.1421 - val_dense_6_loss: 0.0349 - val_dense_7_loss: 0.0012 - val_dense_8_loss: 0.0799 - val_dense_3_acc: 0.9448 - val_dense_4_acc: 0.9452 - val_dense_5_acc: 0.9667 - val_dense_6_acc: 0.9924 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9747\n",
      "Epoch 39/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3844 - dense_3_loss: 0.1378 - dense_4_loss: 0.1294 - dense_5_loss: 0.0669 - dense_6_loss: 0.0141 - dense_7_loss: 2.0651e-04 - dense_8_loss: 0.0360 - dense_3_acc: 0.9560 - dense_4_acc: 0.9588 - dense_5_acc: 0.9782 - dense_6_acc: 0.9958 - dense_7_acc: 1.0000 - dense_8_acc: 0.9875 - val_loss: 0.6832 - val_dense_3_loss: 0.2257 - val_dense_4_loss: 0.2142 - val_dense_5_loss: 0.1393 - val_dense_6_loss: 0.0290 - val_dense_7_loss: 0.0014 - val_dense_8_loss: 0.0736 - val_dense_3_acc: 0.9473 - val_dense_4_acc: 0.9410 - val_dense_5_acc: 0.9671 - val_dense_6_acc: 0.9945 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9777\n",
      "Epoch 40/200\n",
      "241/241 [==============================] - 16s 68ms/step - loss: 0.3864 - dense_3_loss: 0.1409 - dense_4_loss: 0.1311 - dense_5_loss: 0.0655 - dense_6_loss: 0.0116 - dense_7_loss: 1.3076e-04 - dense_8_loss: 0.0373 - dense_3_acc: 0.9556 - dense_4_acc: 0.9574 - dense_5_acc: 0.9791 - dense_6_acc: 0.9966 - dense_7_acc: 1.0000 - dense_8_acc: 0.9878 - val_loss: 0.6871 - val_dense_3_loss: 0.2257 - val_dense_4_loss: 0.2214 - val_dense_5_loss: 0.1380 - val_dense_6_loss: 0.0247 - val_dense_7_loss: 0.0036 - val_dense_8_loss: 0.0738 - val_dense_3_acc: 0.9494 - val_dense_4_acc: 0.9452 - val_dense_5_acc: 0.9675 - val_dense_6_acc: 0.9945 - val_dense_7_acc: 0.9996 - val_dense_8_acc: 0.9781\n"
     ]
    }
   ],
   "source": [
    "# using back the same model\n",
    "\n",
    "H = model.fit_generator(train_gen.generate(), validation_data=val_gen.generate(), steps_per_epoch=train_gen.n_img//BS,\n",
    "                        validation_steps=val_gen.n_img//BS, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"svhn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
