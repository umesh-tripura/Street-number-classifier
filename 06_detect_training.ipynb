{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/yq/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/yq/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from utils.generator import Generator\n",
    "from utils.mean_subtract import MeanSubtract\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        model.add(Conv2D(32, 3, padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(MaxPooling2D(pool_size=3))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(64, 3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(Conv2D(64, 3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, 3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(Conv2D(128, 3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 96\n",
    "height = 96\n",
    "depth = 3\n",
    "BS = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 8,677,252\n",
      "Trainable params: 8,674,372\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SmallerVGGNet.build(width, height, depth)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on extra dataset (pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pickle.load(open(\"rgb_means.pkl\", \"rb\"))\n",
    "ms = MeanSubtract(means[\"R\"], means[\"G\"], means[\"B\"])\n",
    "preprocessors = [ms]\n",
    "\n",
    "generator = Generator(\"bbox/extra.hdf5\", BS, epochs, preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1580/1580 [==============================] - 212s 134ms/step - loss: 439.3331\n",
      "Epoch 2/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 136.8864\n",
      "Epoch 3/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 125.4200\n",
      "Epoch 4/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 117.0011\n",
      "Epoch 5/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 112.8997\n",
      "Epoch 6/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 110.4777\n",
      "Epoch 7/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 107.3164\n",
      "Epoch 8/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 105.3305\n",
      "Epoch 9/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 103.3198\n",
      "Epoch 10/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 101.5092\n",
      "Epoch 11/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 100.6882\n",
      "Epoch 12/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 98.7160\n",
      "Epoch 13/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 97.2899\n",
      "Epoch 14/20\n",
      "1580/1580 [==============================] - 209s 133ms/step - loss: 96.5620\n",
      "Epoch 15/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 95.3761\n",
      "Epoch 16/20\n",
      "1580/1580 [==============================] - 209s 132ms/step - loss: 94.1927\n",
      "Epoch 17/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 93.9710\n",
      "Epoch 18/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 92.6859\n",
      "Epoch 19/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 91.8912\n",
      "Epoch 20/20\n",
      "1580/1580 [==============================] - 210s 133ms/step - loss: 90.1876\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(generator.generate(), steps_per_epoch=generator.n_img//BS, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "train_gen = Generator(\"bbox/train.hdf5\", BS, epochs, preprocessors)\n",
    "val_gen = Generator(\"bbox/val.hdf5\", BS, epochs, preprocessors)\n",
    "\n",
    "callbacks = [LearningRateScheduler(exp_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 142.6494 - val_loss: 126.0216\n",
      "Epoch 2/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 115.8356 - val_loss: 135.4119\n",
      "Epoch 3/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 109.5497 - val_loss: 103.2265\n",
      "Epoch 4/100\n",
      "241/241 [==============================] - 10s 42ms/step - loss: 102.5558 - val_loss: 104.2504\n",
      "Epoch 5/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 97.1273 - val_loss: 104.1343\n",
      "Epoch 6/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 93.5825 - val_loss: 105.5293\n",
      "Epoch 7/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 89.6558 - val_loss: 101.8422\n",
      "Epoch 8/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 88.2924 - val_loss: 99.5892\n",
      "Epoch 9/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 85.2411 - val_loss: 97.6035\n",
      "Epoch 10/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 83.2354 - val_loss: 101.3739\n",
      "Epoch 11/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 81.1815 - val_loss: 103.1565\n",
      "Epoch 12/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 79.2579 - val_loss: 102.6942\n",
      "Epoch 13/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 77.7631 - val_loss: 103.2891\n",
      "Epoch 14/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 76.6933 - val_loss: 101.7534\n",
      "Epoch 15/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 75.5408 - val_loss: 102.1329\n",
      "Epoch 16/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 74.1395 - val_loss: 98.3514\n",
      "Epoch 17/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 73.4459 - val_loss: 100.7270\n",
      "Epoch 18/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 72.4120 - val_loss: 100.2398\n",
      "Epoch 19/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 71.7784 - val_loss: 102.1792\n",
      "Epoch 20/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 71.6118 - val_loss: 99.0104\n",
      "Epoch 21/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 70.7232 - val_loss: 99.1349\n",
      "Epoch 22/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 70.4237 - val_loss: 99.2463\n",
      "Epoch 23/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 69.8394 - val_loss: 97.8162\n",
      "Epoch 24/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 69.1757 - val_loss: 99.7213\n",
      "Epoch 25/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 68.3559 - val_loss: 99.9961\n",
      "Epoch 26/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 68.2747 - val_loss: 101.6691\n",
      "Epoch 27/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 68.0949 - val_loss: 99.5461\n",
      "Epoch 28/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 68.3957 - val_loss: 98.8101\n",
      "Epoch 29/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 67.6904 - val_loss: 96.6134\n",
      "Epoch 30/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 67.3954 - val_loss: 100.6585\n",
      "Epoch 31/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 67.1875 - val_loss: 101.3344\n",
      "Epoch 32/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 67.0170 - val_loss: 100.4298\n",
      "Epoch 33/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 66.4925 - val_loss: 100.2421\n",
      "Epoch 34/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 66.1581 - val_loss: 100.1889\n",
      "Epoch 35/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 66.4337 - val_loss: 101.1737\n",
      "Epoch 36/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 66.9178 - val_loss: 98.0598\n",
      "Epoch 37/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 66.2506 - val_loss: 99.6633\n",
      "Epoch 38/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 67.0331 - val_loss: 98.8117\n",
      "Epoch 39/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 66.0071 - val_loss: 100.4020\n",
      "Epoch 40/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 66.3734 - val_loss: 99.0941\n",
      "Epoch 41/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 66.5669 - val_loss: 99.9894\n",
      "Epoch 42/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.8979 - val_loss: 99.1092\n",
      "Epoch 43/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.3576 - val_loss: 96.8855\n",
      "Epoch 44/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.5968 - val_loss: 99.4025\n",
      "Epoch 45/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.8622 - val_loss: 99.6878\n",
      "Epoch 46/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.9724 - val_loss: 101.1051\n",
      "Epoch 47/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.0559 - val_loss: 99.3535\n",
      "Epoch 48/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.5626 - val_loss: 98.6095\n",
      "Epoch 49/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.2346 - val_loss: 95.7766\n",
      "Epoch 50/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.5176 - val_loss: 100.1463\n",
      "Epoch 51/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.0840 - val_loss: 100.3461\n",
      "Epoch 52/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.5967 - val_loss: 99.8244\n",
      "Epoch 53/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.9811 - val_loss: 99.8318\n",
      "Epoch 54/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.6837 - val_loss: 100.1198\n",
      "Epoch 55/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 65.2796 - val_loss: 100.4921\n",
      "Epoch 56/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.3973 - val_loss: 97.6779\n",
      "Epoch 57/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.2716 - val_loss: 99.1351\n",
      "Epoch 58/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.5253 - val_loss: 98.6000\n",
      "Epoch 59/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.4900 - val_loss: 100.4309\n",
      "Epoch 60/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.0317 - val_loss: 98.9420\n",
      "Epoch 61/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.3676 - val_loss: 99.5965\n",
      "Epoch 62/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.4959 - val_loss: 99.4351\n",
      "Epoch 63/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 64.7247 - val_loss: 97.0127\n",
      "Epoch 64/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 65.8031 - val_loss: 99.0453\n",
      "Epoch 65/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.1889 - val_loss: 100.0398\n",
      "Epoch 66/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.1028 - val_loss: 101.0902\n",
      "Epoch 67/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.3204 - val_loss: 99.4122\n",
      "Epoch 68/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.7724 - val_loss: 98.7807\n",
      "Epoch 69/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.9093 - val_loss: 96.0275\n",
      "Epoch 70/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.2725 - val_loss: 100.6542\n",
      "Epoch 71/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.5624 - val_loss: 100.6640\n",
      "Epoch 72/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 66.0954 - val_loss: 99.4494\n",
      "Epoch 73/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 66.0230 - val_loss: 99.5251\n",
      "Epoch 74/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.2567 - val_loss: 100.2585\n",
      "Epoch 75/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.6462 - val_loss: 101.3450\n",
      "Epoch 76/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.1374 - val_loss: 98.1922\n",
      "Epoch 77/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.7797 - val_loss: 99.5712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 65.4867 - val_loss: 98.6388\n",
      "Epoch 79/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.5711 - val_loss: 100.7474\n",
      "Epoch 80/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 64.7837 - val_loss: 99.0439\n",
      "Epoch 81/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.8228 - val_loss: 99.5532\n",
      "Epoch 82/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 65.4032 - val_loss: 99.0749\n",
      "Epoch 83/100\n",
      "241/241 [==============================] - 10s 44ms/step - loss: 65.1921 - val_loss: 96.8132\n",
      "Epoch 84/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 65.3921 - val_loss: 99.1173\n",
      "Epoch 85/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.2443 - val_loss: 99.5760\n",
      "Epoch 86/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.6453 - val_loss: 100.9758\n",
      "Epoch 87/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 65.2235 - val_loss: 99.3327\n",
      "Epoch 88/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 65.2176 - val_loss: 98.7259\n",
      "Epoch 89/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.1673 - val_loss: 95.7959\n",
      "Epoch 90/100\n",
      "241/241 [==============================] - 10s 42ms/step - loss: 65.3194 - val_loss: 100.2050\n",
      "Epoch 91/100\n",
      "241/241 [==============================] - 10s 42ms/step - loss: 65.4502 - val_loss: 100.4727\n",
      "Epoch 92/100\n",
      "241/241 [==============================] - 10s 42ms/step - loss: 65.3621 - val_loss: 99.8226\n",
      "Epoch 93/100\n",
      "241/241 [==============================] - 10s 42ms/step - loss: 65.6069 - val_loss: 99.8092\n",
      "Epoch 94/100\n",
      "241/241 [==============================] - 10s 43ms/step - loss: 65.2079 - val_loss: 99.6146\n",
      "Epoch 95/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.0723 - val_loss: 100.6724\n",
      "Epoch 96/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 64.7432 - val_loss: 97.7243\n",
      "Epoch 97/100\n",
      "241/241 [==============================] - 11s 45ms/step - loss: 65.2578 - val_loss: 99.2437\n",
      "Epoch 98/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.0749 - val_loss: 99.1728\n",
      "Epoch 99/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.0129 - val_loss: 100.7525\n",
      "Epoch 100/100\n",
      "241/241 [==============================] - 11s 44ms/step - loss: 65.4296 - val_loss: 98.9891\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(train_gen.generate(), validation_data=val_gen.generate(), \n",
    "                        steps_per_epoch=train_gen.n_img//BS, validation_steps=val_gen.n_img//BS,\n",
    "                       epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
